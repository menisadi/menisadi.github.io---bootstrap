<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
<!--     <script async src="https://www.googletagmanager.com/gtag/js?id=UA-57016266-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-57016266-3');
    </script> -->

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="../../favicon.ico">

    <title>Menachem (Meni) Sadigurschi</title>
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

    <!-- Optional theme -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="css/starter-template.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- MathJax -->
    <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Lato|Montserrat|Open+Sans|Roboto|Source+Sans+Pro|Vollkorn|Ubuntu|Titillium+Web|Lora" rel="stylesheet">

  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="index.html">Meni Sadigurschi</a>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li class="active"><a href="index.html">Home</a></li>
            <!-- <li><a href="#about">About</a></li> -->
            <li><a href="publications.html">Publications</a></li>
            <li><a href="teaching.html">Teaching</a></li>
            <li><a href="contact.html">Contact</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">
      <div id="publications" class="starter-template">
        <h2>Publications</h2>
        <ul>
          <li>
            <p>
              <p class=pub-link>On the Sample Complexity of Privately Learning Axis-Aligned Rectangles</a></p>
              <div class=pub-names>Menachem Sadigurschi, <a href="https://www.uri.co.il/">Uri Stemmer</a></div>
              <button class="btn btn-link" onclick="window.location.href='https://arxiv.org/abs/2107.11526';">{Arxiv}</button>
              <button data-toggle="collapse" data-target="#abstract1" class="btn btn-link">{Abstract}</button>
              <p id="abstract1" class="collapse abstract">We revisit the fundamental problem of learning Axis-Aligned-Rectangles over a finite grid <span class="math inline">X^d\subseteq\R^d </span> with differential privacy. Existing results show that the sample complexity of this problem is at most <span class="math inline">\min\left\{ d{\cdot}\log|X| \;,\; d^{1.5}{\cdot}\left(\log^*|X| \right)^{1.5}\right\}</span>. That is, existing constructions either require sample complexity that grows linearly with <span class="math inline">\log|X|</span>, or else it grows super linearly with the dimension <span class="math inline">d</span>. We present a novel algorithm that reduces the sample complexity to only <span class="math inline">\tilde{\mathcal{O}}\left(d{\cdot}\left(\log^*|X|\right)^{1.5}\right)</span>, attaining a dimensionality optimal dependency without requiring the sample complexity to grow with <span class="math inline">\log|X|</span>.The technique used in order to attain this improvement involves the deletion of ``exposed'' data-points on the go, in a fashion designed to avoid the cost of the adaptive composition theorems. The core of this technique may be of individual interest, introducing a new method for constructing statistically-efficient private algorithms. </p>
            </p>
          </li>		
          <li>
            <p>
              <p class=pub-link>Sample Compression for Real-Valued Learners</a>, <a href="http://alt2019.algorithmiclearningtheory.org/"><b>ALT2019</b></p>
              <div class=pub-names><a href="http://www.stevehanneke.com/">Steve Hanneke</a>, <a href="https://www.cs.bgu.ac.il/~karyeh/">Aryeh Kontorovich</a>, Menachem Sadigurschi</div>
              <button class="btn btn-link" onclick="window.location.href='https://arxiv.org/abs/1805.08254';">{Arxiv}</button>
              <button class="btn btn-link" onclick="window.location.href='https://www.youtube.com/watch?v=ueEvY4Ws0l4';">{Video}</button>
              <button class="btn btn-link" onclick="window.location.href='pdf/alt19.pdf';">{Slides}</button>
              <button data-toggle="collapse" data-target="#abstract1" class="btn btn-link">{Abstract}</button>
              <p id="abstract1" class="collapse abstract">We give an algorithmically efficient version of the learner-to-compression scheme conversion in Moran and Yehudayoff (2016). In extending this technique to real-valued hypotheses, we also obtain an efficient regression-to-bounded sample compression converter. To our knowledge, this is the first general compressed regression result (regardless of efficiency or boundedness) guaranteeing uniform approximate reconstruction. Along the way, we develop a generic procedure for constructing weak real-valued learners out of abstract regressors; this may be of independent interest. In particular, this result sheds new light on an open question of H. Simon (1997). We show applications to two regression problems: learning Lipschitz and bounded-variation functions. </p>
            </p>
          </li>
          <li>
            <p>
              <p class=pub-link>Agnostic Sample Compression for Linear Regression</p>
              <div class=pub-names><a href="http://www.stevehanneke.com/">Steve Hanneke</a>, <a href="https://www.cs.bgu.ac.il/~karyeh/">Aryeh Kontorovich</a>, Menachem Sadigurschi</div>
              <button class="btn btn-link" onclick="window.location.href='https://arxiv.org/abs/1810.01864';">{Arxiv}</button>
              <button data-toggle="collapse" data-target="#abstract2" class="btn btn-link">{Abstract}</button>
              <p id="abstract2" class="collapse abstract">We obtain the first positive results for bounded sample compression in the agnostic regression setting. We show that for <span class="math inline">\(p \in \{1,\infty\}\)</span>, agnostic linear regression with <span class="math inline">\(\ell_p\)</span> loss admits a bounded sample compression scheme. Specifically, we exhibit efficient sample compression schemes for agnostic linear regression in <span class="math inline">\(R^d\)</span> of size <span class="math inline">\(d+1\)</span> under the <span class="math inline">\(\ell_1\)</span> loss and size <span class="math inline">\(d+2\)</span> under the <span class="math inline">\(\ell_\infty\)</span> loss. We further show that for every other <span class="math inline">\(\ell_p\)</span> loss (1 &lt; p &lt; <span class="math inline">\(\infty\)</span>), there does not exist an agnostic compression scheme of bounded size. This refines and generalizes a negative result of David, Moran, and Yehudayoff (2016) for the <span class="math inline">\(\ell_2\)</span> loss. We close by posing a general open question: for agnostic regression with <span class="math inline">\(\ell_1\)</span> loss, does every function class admit a compression scheme of size equal to its pseudo-dimension? This question generalizes Warmuthâ€™s classic sample compression conjecture for realizable-case classification (Warmuth, 2003).</p>
            </p>
          </li>
        </ul>
      </div>
    </div><!-- /.container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <!-- Latest compiled and minified JavaScript -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script> -->
  </body>
</html>
